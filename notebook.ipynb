{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data driven Proposal to maximize profit of next market campaign\n",
    "Name: Guilherme Coelho Minervino\n",
    "Live in: Brasília/DF\n",
    "Github: http://github.com/guico3lho\n",
    "Linkedin: https://www.linkedin.com/in/guilherme-coelho-2258751a2/\n",
    "\n",
    "For convention, customers that responded to campaign will be described as **positive customers** and customers that did not responded as **negative customers**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Packages and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import datetime\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Preparing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import dataset from github\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ifood/ifood-data-business-analyst-test/master/ml_project1_data.csv',\n",
    "                 sep=',')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['Income'].isnull()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "Shape (2240, 29)\n",
    "Num_Columns_Numerical = 27\n",
    "Num_Columns_Categorical = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to the fact that 24 rows have NULL values on Income column, we have two options: delete these rows or put the median of the values of all rows to these values. The solution with the best performance was: fill values with median. Despite the accuracy was better when deleting rows with nan values, the f1 score was worse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Besides that, while reading the case, was not clear if 2n Cycle refeers high school or a pos graduation. So, a analysis of Income for each category will be made\n",
    "Reference of 2nCycle pos graduation: https://www.unibo.it/en/teaching/enrolment-transfer-and-final-examination/the-university-system/what-is-a-second-cycle-degree-programme"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df = df.dropna()\n",
    "df['Income'].fillna(df['Income'].median(), inplace=True)\n",
    "\n",
    "df.groupby('Education')['Income'].mean().sort_values(ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "Based on the results, 2n Cycle was the second lowest income, so it can be presumed that 2n Cycle corresponds to High school, not a pos-graduation\n",
    "That information will be further used to encode these categories to numerical (OrdinalEncoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are two columns of type categorical and one column of type date\n",
    "Lets see how many categories there are on the categorical ones"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pp = df.copy()\n",
    "display(df_pp['Education'].value_counts())\n",
    "display(df_pp['Marital_Status'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "With the goal to perform better exploratory analysis and predictions, it is necessary to convert columns Dt_customer (Date string), Education (Categorical ordinal), Marital_Status (Categorical nominal) to numeric representation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# Categorizando coluna Education seguindo uma ordem de hierarquia crescente (Basic (0) -> PhD (4))\n",
    "categories = [['Basic', '2n Cycle', 'Graduation', 'Master', 'PhD']]\n",
    "ordinalEncoder = OrdinalEncoder(categories=categories)\n",
    "df_pp['Education_Cat'] = ordinalEncoder.fit_transform(df_pp['Education'].values.reshape(-1, 1))\n",
    "df_pp['Education_Cat'] = df_pp['Education_Cat'].astype(int)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "The OrdinalEncoder was used because the Education column has ordinal categories (categories has a hierarchy between them)\n",
    "Basic, 2n Cycle, Graduation, Master, PhD will recieve a value (weight) of 0, 1, 2, 3, 4, respectively"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Categorizando coluna Marital Status utilizando get_dummies, já que a ordem das categorias não é importante\n",
    "df_pp = pd.get_dummies(df_pp, columns=['Marital_Status'], prefix=['Marital_Type'])\n",
    "df_pp['Marital_Status'] = df['Marital_Status']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "get_dummies was used because Marital_Status does not have hierarchy between them (nominal categories). Each category will recieve its own column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transforming date column to number"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pp['Dt_Customer_Number'] = df_pp['Dt_Customer'].apply(lambda x: int(round(datetime.datetime.strptime(x, '%Y-%m-%d').timestamp())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shift response column to the end of df\n",
    "df_columns = [col for col in df_pp.columns if col != 'Response']\n",
    "df_columns.insert(len(df_pp), 'Response')\n",
    "df_pp = df_pp[df_columns]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "df after all pre processings:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "10 columns were added due to the numericalization of columns Education, Marital_Status and Dt_Customer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Exploratory Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1. Analyzing 10 samples (5 with target = 1 and 5 with target = 0)\n",
    "Objective: find nice features and bad features and insights about future analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "samples = df_pp.sort_values(by=['Response'], ascending=False).groupby('Response').head(5)\n",
    "samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes on the sample of size 10 (Initial hypotheses):\n",
    "- Columns correlated to Response: MntFruits,Meat,Fish,Hold; NumWebPurchases,CatalogPurchases; Education; Marital_Status\n",
    "- Positive costumers spend more on Wines, Meat, Fish, Gold Prdocuts than negative customers\n",
    "- Positive costumers have better education and fewer kids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Lets see the statistics about data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pp.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "Study about describe() func\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Lets see the balancement of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pp['Response'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "- The dataset is imbalanced\n",
    "- Percentage of customers that responded to campaign: 15%\n",
    "- Percentage of customers that not responded to campaign: 85%\n",
    "- Therefore, can be presumed that future machine learning models will be better at predicting negative customers (0) than predicting negative customers (1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 Lets see the mean of each column based on target label (Response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3_4 = df_pp.groupby('Response').mean()\n",
    "df_3_4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "OBS:\n",
    "- Columns Z_CostContact and Z_Revenue did not appear due to constant nature for all samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "Considering df_3_4:\n",
    "- Positive customers have 10k higher income than negative customers\n",
    "- Negative customers have more Kids and Teens than positive customers\n",
    "- Negative customers take longer time to do another purchase than positive customers\n",
    "- Positive customers buy almost double quantity of Wines and Meat than negative customers\n",
    "- Positive customers buy more Fruits, Fish, Sweet and Gold than negative customers\n",
    "- Positive customers buys more using Catalog than negative customers\n",
    "- Positive customers buy more on Web than negative customers, despite the number of WebVisits of each is very similar (Therefore, the chance of Positive customers buy a product on Web is higher than negative customers\n",
    "- Considering all previous Campaigns, positive customers responded better than negative customers\n",
    "- Was expected to Complain be higher on negative customers. But the data showed they have approximate values\n",
    "- Education of positive customers is higher than negative\n",
    "- Looking at Marital_status columns, can be inferred that the new gadget is more acceptable by single people (Single or Divorced)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "- Year_Birth, Income, MntWines, MntMeat, MntFish, MntSweet, MntGold, NumCatalog, NumWeb, AcceptedCmp[1-5], Education, Alone, Divorced, Single, Widow, Absurd was higher for Response = 1\n",
    "- Kidhome, Teenhome, Recency, Maried, Together was higher for Response = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Visualizations\n",
    "Let's drop columns that does not give information\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_4 = df_pp.copy()\n",
    "df_4 = df_4.drop(['ID', 'Z_CostContact', 'Z_Revenue', 'Education', 'Marital_Status'], axis=1)\n",
    "df_4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Univariate Plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_4.hist(figsize=(15, 25))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "- There are much more people with a Graduation than other educations\n",
    "- The distribution for Fish, Fruit, Wine is low. Makes sense, since there are close to 6 times more negative customers than positive customer and, as seen on section 3.4, negative customers does not spend much on these products rather positive customers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Multivariate Plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_4_2 = df_4.copy()\n",
    "df_4_2 = df_4_2.loc[:, ['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']]\n",
    "scatter_matrix(df_4_2, figsize=(10, 12))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_4_2 = df_4.copy()\n",
    "df_4_2 = df_4_2.loc[:, ['MntWines', 'MntFruits',\n",
    "                        'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'Response']]\n",
    "scatter_matrix(df_4_2, figsize=(12, 12),alpha=0.1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "It can be perceived from the hist above that:\n",
    "- Fish, Meat, Fruit Wines has a positive correlation between them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_4_2 = df_4.copy()\n",
    "df_4_2 = df_4_2.loc[:, ['NumDealsPurchases', 'NumWebPurchases',\n",
    "                        'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Response']]\n",
    "scatter_matrix(df_4_2, figsize=(10, 12),alpha=0.1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "- None insight was obtained from hist above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_4_2 = df_4.copy()\n",
    "df_4_2 = df_4_2.loc[:, ['Year_Birth', 'Education_Cat', 'Income', 'Kidhome',\n",
    "                        'Teenhome', 'Dt_Customer', 'Recency', 'Response']]\n",
    "scatter_matrix(df_4_2, figsize=(10, 12))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "plt.show()\n",
    "Notes:\n",
    "- None insight was obtained from hist above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "- Can be said that Higher Wine and Meet, higher the chance that is a positive customer\n",
    "- Can be said that lower the store purchases, higher the chance that is a negative customer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Confirming notes above using corr()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = df_pp.corr()\n",
    "corr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "Analyzing the correlation, a new feature was found relevant: Dt_Customer_Number. Older the customer, higher the chance that will be the gadget\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Customer segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KMeans will be used to see the cluster formed by features MntWines, MntMeat and Response, to prove that the high value of these features means a higher chance of Response = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A normalization on data is needed because KMeans used the concept of distance. So, on each column will be applied log function and StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def log_alt(x):\n",
    "    if np.log(x) < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = df_pp[[\"MntWines\", \"MntMeatProducts\", \"Response\"]]\n",
    "\n",
    "df_log = pd.DataFrame()\n",
    "df_log['MntWines'] = data['MntWines'].apply(log_alt)\n",
    "df_log['MntMeatProducts'] = data['MntMeatProducts'].apply(log_alt)\n",
    "df_log['Response'] = data['Response']\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "df_scaled = std_scaler.fit_transform(df_log)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "erros = []\n",
    "for k in range(1,11):\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(df_scaled)\n",
    "    erros.append(model.inertia_)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Error of cluster')\n",
    "sns.pointplot(x=list(range(1,11)), y=erros)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The theory of the elbow says that the optimal number of clusters is when the elbow is formed e.g. N = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3, random_state=2)\n",
    "model.fit(df_scaled)\n",
    "data = data.assign(ClusterLabel = model.labels_)\n",
    "data.groupby(\"ClusterLabel\")[[\"MntWines\", \"MntMeatProducts\", \"Response\"]].median()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(\n",
    "    data_frame=data,\n",
    "    x=\"MntWines\",\n",
    "    y=\"MntMeatProducts\",\n",
    "    z=\"Response\",\n",
    "    title = \"Relationship between MntWines, MntMeatProducts, Response\",\n",
    "    color=\"ClusterLabel\",\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "As Cluster 2 represent Response = 1 and Cluster 1 and 0 represent Response - 0,\n",
    "The 3d graph and table shows that positive customers spends more than 200 on meat products and more than 460 on wine products"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Classification metodologies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluateModels(X_train, y_train, models, n_splits):\n",
    "    print(f\"{n_splits}-Fold Cross validation\")\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2)\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print(f\"{name}: Mean Accuracy={cv_results.mean():.5f}, Standard Deviation={cv_results.std():.5f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Models:\n",
    "    def __init__(self, X_train, X_test , y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def logistic_regression(self):\n",
    "        print(\"Logistic Regression\")\n",
    "        self.name = 'Logistic Regression'\n",
    "        self.classifier = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.classifier.predict(self.X_test)\n",
    "\n",
    "    def svm(self):\n",
    "        self.name = 'SVM'\n",
    "        print(\"SVM\")\n",
    "        # self.classifier = SVC(C=1.0, kernel='linear', degree=3, gamma='auto',random_state=0)\n",
    "        self.classifier = SVC(gamma='auto')\n",
    "\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.classifier.predict(self.X_test)\n",
    "\n",
    "    def k_neighbors(self, n_neighbors):\n",
    "        self.name = 'K Neighbors'\n",
    "        print(\"KNN, n_neighbors = {}\".format(n_neighbors))\n",
    "        # self.classifier = KNeighborsClassifier(n_neighbors=5, metric='cosine', p=2)\n",
    "        self.classifier = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean')\n",
    "\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.classifier.predict(self.X_test)\n",
    "\n",
    "    def score(self, type='cr'):\n",
    "        self.score1 = accuracy_score(self.y_test, self.y_pred)\n",
    "        self.score2 = precision_score(self.y_test, self.y_pred)\n",
    "        self.score3 = recall_score(self.y_test, self.y_pred)\n",
    "        self.score4 = f1_score(self.y_test, self.y_pred)\n",
    "        self.cm = confusion_matrix(self.y_test, self.y_pred)\n",
    "\n",
    "        if (type == 'scores'):\n",
    "\n",
    "            print(\"---- Scores ----\")\n",
    "            print(\"Accuracy score is: {}%\".format(round(self.score1 * 100, 2)))\n",
    "            print(\"Precision score is: {}\".format(round(self.score2 * 100, 2)))\n",
    "            print(\"Recall score is: {}\".format(round(self.score3 * 100, 2)))\n",
    "            print(\"F1 score is: {}\".format(round(self.score4 * 100, 2)))\n",
    "        elif (type == 'cr'):\n",
    "            print(\"---- Classification Report ----\")\n",
    "            print(classification_report(self.y_test, self.y_pred))\n",
    "\n",
    "        elif (type == 'cm'):\n",
    "            print(\"---- Confusion Matrix ----\")\n",
    "\n",
    "            self.show_confusion_matrix()\n",
    "\n",
    "    def show_confusion_matrix(self):\n",
    "        print(\"Confusion Matrix\")\n",
    "        plt.figure(figsize=(5, 5))\n",
    "\n",
    "        sns.heatmap(self.cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'],\n",
    "                    yticklabels=['Negative', 'Positive'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Truth')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metodology 1\n",
    "- Use features more correlated with target Response for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preparing data for input to model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get column names more correlated to Response (abs >= 0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get columns more correlated\n",
    "df_more_corr = corr.loc[abs(corr['Response']) >= 0.09]\n",
    "columns_more_corr = df_more_corr.index.tolist()\n",
    "# create dataframe with these columns\n",
    "df_m1 = df_pp[columns_more_corr]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split array into features and target label\n",
    "m1_array = df_m1.values\n",
    "X = m1_array[:, :-1]\n",
    "y = m1_array[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normalize features\n",
    "ss = MinMaxScaler()\n",
    "X = ss.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "Was decided to use the MinMaxScaler normalization because the models had of 2% increase of accuracy in comparison to not using any kind of normalization\n",
    "\n",
    "This normnaization maps each column to a range of 0 to 1, based on the max value of the columns and the minimum value of the column to decide the final value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, random_state=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluating models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Was decided to use cross validation on the train_splits (using one part for train and another part for validation) and leaving test_split for the final test. This method will be used because all the train data will be used as validation at some point. After cross validation, the best model will be used on unseen data (test_split). Then can be evaluated if the model is overfitted on trained data or not)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluating models\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "\n",
    "evaluateModels(X_train,y_train, models, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating the 4 models above using only train_split (90% as train/ 10% as validation iteratively), Logistic Regression showed the best results, with 89% of mean accuracy considering the 10 rounds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predictions\n",
    "- Now that the best models was evaluated, it is time to test it on unseen data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "models = Models(X_train, X_test, y_train, y_test)\n",
    "models.logistic_regression()\n",
    "print(f\"Methodology 1 Results\")\n",
    "models.score()\n",
    "models.show_confusion_matrix()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cost-Revenue Confusion Matrix\n",
    "Considering the confusion matrix idea and the columns Z_CustomerCost and Z_Revenue, I propose the Cost-Revenue Confusion Matrix with the goal to calculate the profit of the model\n",
    "Properties:\n",
    "- 2x2 shape\n",
    "- If a customer is TP, means that the company had the cost of 3 but revenue of 11, resulting on 8 of profit (because the model predics that the customer wil buy and he will)\n",
    "- If a customer is FP, means that the company had the cost of 3 but revenue of 0, resulting on -3 of profit (because the model predics that the customer will buy and he dont)\n",
    "- If a customer is FN, means that the company would have \"possible\" cost of 3 and \"possible\" revenue of 11, resulting on -8 of profit (because that they did not profit with a positive customer, can be inferred a profit of 0 too, but I decided the profit of -11 MUs for convention)\n",
    "- If a customer is TN, means that the company had the cost of 0 and \"deduction\" of 3, resulting on 3 of profit (because the model predicts that the customer wont buy and he dont, saving 3 MUs)\n",
    "- Therefore, each customer on TP will score 8 points to the final profit\n",
    "- each customer on FP will score -3 on final profit\n",
    "- And there goes...\n",
    "- The final profit can be calculated using the scalar product of the two matrices (A.B)\n",
    "\n",
    "Therefore, The confusion matrix:\n",
    "|TN FP|\n",
    "|FN TP|\n",
    "\n",
    "Will be mapped to:\n",
    "|3 -3|\n",
    "|-8 8|\n",
    "\n",
    "Based on that mapping, the following metrics is considered the best:\n",
    "- recall because we want to minimize FN cases (profit of -8) and maximize TP (profit of 8)\n",
    "- accuracy because pursuit to maximize TP (deduction 3) and TN (profit of 8) cases\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, the model had 98% of recall on negative customers and 39% of recall on positive customers and a Accuracy of 87%\n",
    "Based on that, the profit can be calculated by:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix_m1 = models.cm\n",
    "cost_revenue_confusion_matrix_m1 = np.array([[3,-3],[-8,8]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making scalar product"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_profit_m1 = np.dot(confusion_matrix_m1.reshape(4), cost_revenue_confusion_matrix_m1.reshape(4))\n",
    "print(f\"The final profit for methodology 1 is {final_profit_m1} MUs\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metodology 2\n",
    "- Use all features for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preparing data for input to model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_m2 = df_pp.copy()\n",
    "df_m2.drop(columns=['Education', 'Marital_Status','Dt_Customer','Z_Revenue','Z_CostContact'], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m2_array = df_m2.values\n",
    "X = m2_array[:, :-1]\n",
    "y = m2_array[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ss = MinMaxScaler()\n",
    "X = ss.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, random_state=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluating models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "\n",
    "evaluateModels(X_train, y_train, models, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "LR was the best model using StratifiedKfold and 80/20 train_test_split, with 0,89107 of accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to the fact that LR got the best results, it will be used for the final test: use the model for unseen data (test_split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predictions\n",
    "- Now that the best models was evaluated, it is time to test it on unseen data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = Models(X_train, X_test, y_train, y_test)\n",
    "models.logistic_regression()\n",
    "print(f\"Methodology 1 Results\")\n",
    "models.score()\n",
    "models.show_confusion_matrix()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cost-Revenue Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, the model had 98% of recall on negative customers and 42% of recall on positive customers and a Accuracy of 88%\n",
    "Based on that, the profit can be calculated by:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix_m1 = models.cm\n",
    "cost_revenue_confusion_matrix_m1 = np.array([[3, -3], [-8, 8]])\n",
    "\n",
    "final_profit_m1 = np.dot(confusion_matrix_m1.reshape(4), cost_revenue_confusion_matrix_m1.reshape(4))\n",
    "print(f\"The final profit for methodology 2 is {final_profit_m1} MUs\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Conclusion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- It is important to note that the model will be better at predicting right customers that will not respond to the compaign (TN) than predicting right customers that will respond (TP) due to the fact that the dataset is unbalanced\n",
    "\n",
    "- I exptected the model using only features more correlated to Response (target) will be better (Methodolgy 1). But, surpsingly, the other model did best, with a profit of 805 MUs, accuracy of 88% and recall of 42% againist 754 MUs, 87% of accuracy and 39% of recall for Methodology 2\n",
    "\n",
    "- It is important that to tell CMO that if a customer has low recency, long date customer, doesnt have teen or kids, is not married (five features more negative correlated to response), accepted the campaigns 1,3 or 5 and spend a lot with Wines or Meat(five features more positve correlated to response), the chance to be a positive customer (buy the gadget) is extremely high"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. References\n",
    "https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n",
    "https://towardsdatascience.com/data-exploration-and-analysis-using-python-e564473d7607\n",
    "https://medium.com/ml-research-lab/chapter-4-knowledge-from-the-data-and-data-exploration-analysis-99a734792733\n",
    "https://www.freecodecamp.org/news/customer-segmentation-python-machine-learning/\n",
    "Data Science Do Zero: Noções Fundamentais com Python, 2021 - Joel Grus"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
